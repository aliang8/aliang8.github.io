\begin{itemize}
  \item desire to build systems that learn and think like people
  \item machines should build causal models of the world that support explanation and understanding and not just pattern recognition
  \item ground learning in \red{intuitive physics}
  \item harness \red{compositionality} and \red{learning-to-learn}, rapidly acquire knowledge to new tasks and situations
  \item deep learning models may be solving the problems differently than people do
  \item Prediction versus explanation
  \item Developmental start-up software, cognitive capabilities that are present early in development
    \begin{itemize}
      \item 1) intuitive physics
      \item primitive object concepts that allow them to track objects over time and discount physically implausible trajectories
      \item new task, but physics still works the same way
      \item 2) \red{intuitive psychology}
      \item understanding that people have mental states like goals and beliefs
    \end{itemize}
  \item \red{model-building} is the basis of human-level learning
  \item compositionality and learning-to-learn can make rapid model learning possible
  \item we are incredibly fast at perceiving and acting
  \item neural networks are designed for pattern-recognition rather than model-building
  \item integrate NN with rich model-building mechanisms can explain how human minds understand the world so well, so quickly
  \item humans can learn a lot more from a lot less
  \item single example of a new visual concept can be enough information to support: classification of new examples, generation of new examples, parsing object into parts and relations, and generation of new concepts
  \item DQN, simple model-free RL algorithm, that learns to play the game Frostbite
  \item visual system and policy are highly specialized to the games that it was trained on
  \item DQM plays games at human-level performance, but it is doing so in a way different than humans
  \item DQN trained on 200 million frames, 924 days, about 500 times more training experience as a human, not sample efficient
  \item Fundamental differences in representation and learning between people and DQN
  \item DQN relies on some reward function, otherwise take random actions
  \item DQN is inflexible to changes in inputs and goals, e.g. changing color of object will be harmful to performance
  \item People can understand the game + goals quickly. Moreover, people understand enough to invent new goals, generalize changes to input, and explain the game to others
  \item How do we bring to bear rich prior knowledge to learn new tasks and solve new problems quickly?
  \item Intuitive physics-engine approach to scene understanding
  \item PhysNet used DCNN to predict stability of block towers from simulated images
  \item Could neural networks be trained to emulate a general-purpose physics simulator?
  \item Integrating intuitive physics and DL could be important to more human-like learning algorithms
  \item Intuitive psychology can allow us to infer the beliefs, desires, and intentions of others (e.g. avoiding bird in Frostbite game)
  \item Injecting inductive bias can boostrap reasoning about abstract concepts
  \item One-shot learning is innate characteristic of humans from a young age
  \item Compositionality is the idea that new representations can be constructed from the combination of primitive elements
  \item Object-oriented reinforcement learning, representing a scene as a composition of objects
  \item compositionality is important at the level of goals and subgoals
  \item causality is a subclass of generative models that resemble how the data are actually generated
  \item causality can glue features together by relating them to a deep underlying cause
  \item perception without key ingredients and absence of causal glue can lead to errors
  \item network can get the objects correctly but fail to understand the physical forces at work
  \item learning to learn, learning a new task can be accelerated through previous or parallel learning of related tasks
  \item people transfer knwoledge at multiple-levels, learn compositionally structured causal models of a game
  \item there is evidence that suggests our brain has a model-based learning system, building a map of the environment and using it to plan action sequences for complex tasks
  \item Intrinsically motivated learning
  \item Responses to common questions
  \begin{itemize}
    \item It is unfair to compare learning speeds of human and machine because of apriori knowledge / experience
    \item Neuroscience in the long run will place more constraints on theories of intelligence
    \item Language is essential to human intelligence and goes hand in hand with other key ingredients
    \item Language facilitates more powerful learning-to-learn and compositionality, allow people to learn more quickly and flexibly
  \end{itemize}
  \item AI has made incredible progress: beat chess masters, Jeopardy champions, facial recognition, speech understanding
  \item More exciting applications to come: self-driving, medicine, drug design, genetics, and robotics
  \item Recent advancements in incorporating psychological ingredients with deep networks: selective attention, augmented memory, experience replay
  \item Attention allows the model to focus on smaller sub-tasks rather than solving whole problem in one-shot
  \item Memory incorporates classical data structures into gradient-based learning systems
  \item AI systems like AlphaGo are trained on millions of self-play games whereas world champion probably only played 50,000 games in his lifetime
  \item Proposed goal: systems should see objects rather than features, build causal models and not just recognize patterns, recombine representations without retraining, and learning-to-learn rather than starting from scratch
\end{itemize}