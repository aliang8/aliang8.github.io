\documentclass[../main.tex]{subfiles}

\newenvironment{conditions}
  {\\ \vspace{\abovedisplayskip}\noindent\begin{tabular}{>{$}l<{$} @{${}={}$} l}}
  {\end{tabular}\par\vspace{\belowdisplayskip}}

\begin{document}
\section{Bayes Filter}
  \begin{itemize}
    \item Bayes Filter accounts for both robot state and perception data
    \item To use Bayes filter, the state must be discrete, usually represented by a grid
    \item Each grid cell, contains the \textbf{belief} (probability that the true state of the system is $x_{t}$)
  \end{itemize}

  \begin{algorithm}[H]
      \SetAlgoLined
      Inputs: Bel(x), d\;
      $\eta = 0$\;
      \If{d is a perceptual data item $z$}{
        \For{all x}{
          $Bel'(x) = P(z|x)Bel(x)$\;
          $\eta = \eta + Bel'(x)$\;
        }
        \For{all x}{
          $Bel'(x) = \eta^{-1}Bel'(x)$\;
        }
      }
      \ElseIf{d is an action data item $u$ then}{
        \For{all x}{
          $Bel'(x) = \sum_{x'}P(x|u,x')Bel(x')$\;
        }
      }
      Return $Bel'(x)$
      \caption{Discrete Bayes Filter Algorithm}
  \end{algorithm}

\section{Kalman Filter}
  \begin{itemize}
      \item Kalman filter used when state space is continuous variables
      \item They key idea is to represent everything with \textit{gaussians}
      \item Univariate and multivariate gaussians
      \item We stay in "Gaussian world" as long as we start with Gaussians and perform only linear transformations
      \item Estimate state $x$ of a \textit{discrete-time} controlled process governed by linear stochastic difference equation:
      \begin{equation*}
        x_{t} = A_{t}x_{t-1} + B_{t}u_{t} + \epsilon_{t}
      \end{equation*}
      and sensor measurement
      \begin{equation*}
        z_{t} = C_{t}x_{t} + \delta_{t}
      \end{equation*}
      where:
      \begin{conditions}
        x_{t} & current state \\
        A_{t} & matrix describing how state changes from $t-1$ to $t$ without controls \\
        B_{t} & matrix that describes how control $u_{t}$ changes the state from $t-1$ to
        $t$ \\
        C_{t} & matrix that describes how to map state $x_{t}$ to an observation $z_{t}$ \\
        \epsilon_{t} & process noise normally distributed with covariance $R_{t}$ \\
        \delta_{t} & measurement noise normally distributed with covariance $Q_{t}$ \\
      \end{conditions}
      \begin{algorithm}[H]
          \SetAlgoLined
          Prediction: use dynamics to predict what will happen\;
          $\bar{\mu_{t}} = A_{t}\mu_{t-1} + B_{t}u_{t}$\;
          $\bar{\Sigma_{t}} = A_{t}\Sigma_{t-1}A_{t}^{T} + R_{t}$\;
          Correction: use sensor measurement to correct prediction\;
          $K_{t} = \bar{\Sigma_{t}}C_{t}^{T}(C_{t}\bar{\Sigma_{t}}C_{t}^{T} + Q_{t})^{-1}$\;
          $\mu_{t} = \bar{\mu_{t}} + K_{t}(z_{t} - C_{t}\bar{\mu_{t}}$\;
          $\Sigma_{t} = (I - K_{t}C_{t})\bar{\Sigma_{t}}$\;
          \Return{$\mu_{t}, \Sigma_{t}$}
          \caption{Kalman Filter}
      \end{algorithm}
      \item Comments:
        \begin{itemize}
            \item Highly efficient: only need to compute matrix multiplication
            \item Optimal for linear Gaussian systems, but most robotics systems are nonlinear
        \end{itemize}
  \end{itemize}

\section{Extended Kalman Filter (EKF)}
  \begin{itemize}
      \item Most robotics problem deal wth nonlinear dynamics and sensors
      \begin{equation*}
        x_{t} = g(u_{t}, x_{t-1})
      \end{equation*}
      \begin{equation*}
        z_{t} = h(x_{t})
      \end{equation*}
      \item EKF trick: use a \textit{local linear approximation} by computing the Jacobians of $g$ and $h$
      \begin{equation*}
        x_{t} = g(u_{t}, x_{t-1}) \approx g(u_{t}, \mu_{t-1}) + G_{t}(x_{t-1} - \mu_{t-1})
      \end{equation*}
      \begin{equation*}
        z_{t} = h(x_{t}) \approx h(\bar{\mu_{t}}) + H_{t}(x_{t} - \bar{\mu_{t}})
      \end{equation*}
      where
      \begin{conditions}
        G_{t} & $\frac{\partial{g(u_{t}, \mu_{t-1})}}{\partial x_{t-1}}$ \\
        H_{t} & $\frac{\partial h(\bar{\mu_{t}})}{\partial x_{t}}$
      \end{conditions}
      \item Comments
      \begin{itemize}
        \item Highly efficient
        \item Not optimal, because it is an approximation of the nonlinear function
        \item Can diverge if nonlinearities are large (e.g. close to beacon)
        \item Everything must be a Gaussian
        \item Cannot be used if transition is non-linear, e.g. multimodal distributions
      \end{itemize}
  \end{itemize}

\section{Unscented Kalman Filter}
  \begin{itemize}
    \item Key idea:
      \begin{enumerate}
        \item Sample a set of sigma points from Gaussian distribution
        \item Pass sigma points through function
        \item Re-estimate Gaussian
      \end{enumerate}
    \begin{algorithm}[H]
        \SetAlgoLined
        $\mathcal{X}_{t-1} = $ Compute sigma points using $\mu_{t-1}$ and $\Sigma_{t-1}$\;
        $\bar{\mathcal{X}_{t}^{*}} = g(u_{t}, \mathcal{X}_{t-1})$ // Apply dynamics \;
        $\bar{\mu_{t}} = \sum_{i=0}^{2n} w_{m}^{[i]} \bar{\mathcal{X}_{t}^{*}}^{[i]}$ // Estimate new mean from sigma points\;
        $\bar{\Sigma_{t}} = \sum_{i=0}^{2n} w_{c}^{[i]} (\bar{\mathcal{X}_{t}^{*}}^{[i]} - \bar{\mu_{t}})(\bar{\mathcal{X}_{t}^{*}}^{[i]} - \bar{\mu_{t}})^{T} + R_{t}$\;
        $\bar{\mathcal{X}_{t}} = $ Compute sigma points using $\bar{\mu_{t}}$ and $\bar{\Sigma_{t}}$\;
        $\bar{\mathcal{Z}_{t}} = h(\bar{\mathcal{X}_{t}})$ // Apply sensor model\;
        TODO\;
        \caption{Unscented Kalman Filter}
    \end{algorithm}
    \item Comments
      \begin{itemize}
        \item Highly efficient
        \item Better approximation than EKF: accurate in first two terms of Taylor expansion
        \item Derivative-free, does not require any Jacobians
      \end{itemize}
  \end{itemize}

\section{Particle Filter}
  \begin{itemize}
    \item No need to make assumptions of distributions unlike Kalman Filter which assumes that all error is Gaussian
    \item Sample from the implicit distribution of the state at any given time
    \item At time $t$, distribution is represented by the M samples of the robot's states
    \begin{equation*}
      X_{t} = x_{t}^{[1]}, x_{t}^{[2]}, ..., x_{t}^{[M]}
    \end{equation*}
    \begin{equation*}
      W_{t} = w_{t}^{[1]}, w_{t}^{[2]}, ..., w_{t}^{[M]}
    \end{equation*}
    \item If starting location is know, can initialize particles around start, else scatter particles through the environment

    \begin{algorithm}[H]
        \SetAlgoLined
        $X_{0} = $ Sample M particles from $P(X_{0})$\;
        $t = 0$\;
        \While{True} {
          $t++$\;
          $u_{t} = $ action()\;
          $z_{t} = $ sensor()\;
          $S_{t} = X_{t} = \{\}$\;
          \For{m = 1 to M}{
            sample $x_{t}^{[m]} \sim$ $p(x_{t} | u_{t}, x_{t-1}^{[m]}$ \text{from} $X_{t-1})$\;
            $w_{t}^{[m]} = p(z_{t} | x_{t}^{[m]})$\;
            $S_{t} = S_{t} \cup (x_{t}^{[m]}, w_{t}^{[m]})$\;
          }
          \For{m = 1 to M} {
            draw $i$ with probability $\sim w_{t}^{[i]}$\;
            add $x_{t}^{[i]}$ from $S_{t}$ to $X_{T}$\;
          }
        }
        \caption{Particle Filter}
    \end{algorithm}
    \item Sampling strategies
      \begin{itemize}
        \item Need to preserve diversity of particles, inject random particles
        \item Low-variance sampling
        \item Stratified sampling
      \end{itemize}

    \item Comments
      \begin{itemize}
        \item Represent distribution with a set of particles
        \item Approximate arbitrary probability distributions
        \item More particles = better approximation but more computation cost
      \end{itemize}
  \end{itemize}

\end{document}